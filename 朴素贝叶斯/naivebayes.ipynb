{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯是基于贝叶斯定理与特征条件独立假设的分类方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要明白什么是贝叶斯定理，则先复习一下几个术语：条件概率、特征条件独立假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么是条件概率？\n",
    "\n",
    "$P(A|B)$表示事件B已经发生的前提下，事件A发生的概率，也叫做事件B发生下事件A的条件概率。上述用数学语言描述为：\n",
    "$${P(A|B)=\\frac{P(AB)}{P(B)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯定理是基于条件概率，通过$P(A|B)$来求解$P(B|A)$：$P(B|A)=\\frac{P(A|B)P(B)}{P(A)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据全概率公式，上式又可以写为:\n",
    "$${P(B_i|A)=\\frac{P(B_i)P(A|B_i)}{\\sum_{j=1}^{n} P(B_j)P(A|B_j)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面介绍了条件概率，那什么是特征条件独立假设？\n",
    "\n",
    "给定训练集$(X,Y)$,$x$是集合$X$中的样本($x \\in X$),$x=(x_1,x_2,...,x_n)$,类标记集合含有$K$中类别，及$\\mathcal{Y}=\\{c_1,c_2,...,c_K\\}$.\n",
    "\n",
    "如何预测新样本$x$的类别呢？从概率的角度分析，该问题的本质就是**<font color=red>给定$x$，它属于哪个类别的概率最大</font>**.  \n",
    "即问题转化为求解$P(Y=c_1|X=x),P(Y=c_2|X=x),...,P(Y=c_k|X=x)$中最大的概率，即求后验概率最大输出:${\\arg \\max_{c_k} P(Y=c_k|X=x)}$.后验概率最大的类作为$x$的类别输出."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要求后验概率最大输出:${\\arg \\max_{c_k} P(Y=c_k|X=x)}$，也就是要求出:${P(Y=c_k|X=x)}$.想要求出${P(Y=c_k|X=x)}$，就要用到贝叶斯定理，根据贝叶斯定理，可得：\n",
    "$${P(Y=c_k|X=x)=\\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_{k} P(X=x|Y=c_k)P(Y=c_k)}}  \\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对条件概率$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)})$,假设第$i$维特征$x_i$可取值有$S_j$个，类别取值个数为$K$个，那么参数个数为:$K \\prod_{j=1}^{n}S_j$,其规模为指数数量级别的。这在实际应用中肯定不行的。\n",
    "\n",
    "为了解决这个问题，朴素贝叶斯法对条件概率分布作了条件独立性的假设,即**<font color=red>假设各个维度的特征$x_1,x_2,...,x_n$互独立</font>**.\n",
    "\n",
    "有了这个假设，条件概率可以转化为：\n",
    "$${P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)})}=\\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_k)  \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将式子(2)带入式子(1)可得：\n",
    "$${P(Y=c_k|X=x)=\\frac {P(Y=c_k) \\prod_{j} P(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_k P(Y=c_k) \\prod_j P(X^{(j)}=x^{(j)}|Y=c_k)}},k=1,2,...,K  \\tag{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "式子(3)位朴素贝叶斯分类的基本公式。即 朴素贝叶斯分类器可由下式子表示：\n",
    "$${y=f(x)=\\arg \\max_{c_k} \\frac {P(Y=c_k) \\prod_{j} P(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_k P(Y=c_k) \\prod_j P(X^{(j)}=x^{(j)}|Y=c_k)}} \\tag{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于对于所有的$c_k$，上式子分母的值是一样的，所以可以忽略掉分母部分。最终朴素贝叶斯分类器的表达式为：\n",
    "$${y=\\arg \\max_{c_k} P(Y=c_k) \\prod_{j} P(X^{(j)}=x^{(j)}|Y=c_k)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述的表述是从头到尾推导出朴素贝叶斯分类器的过程.\n",
    "\n",
    "**若对推导过程不感兴趣，可跳过上述推导，直接看下面朴素贝叶斯分类算法：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本方法：\n",
    "\n",
    "设输入空间$\\mathcal{X}\\subseteq \\mathcal{R}^n$是$n$维向量的集合，输出空间为类标记集合$\\mathcal{Y}=\\{c_1,c_2,...,c_K\\}$.其中特征向量${x}\\in \\mathcal{X}$作为输入,类标记$y\\in \\mathcal{Y}$作为输出。\n",
    "\n",
    "训练集$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$由$P(X,Y)$独立同分部产生。其中$X$是定义在输入空间$\\mathcal{X}$上的随机向量，$Y$是定义在输出空间$\\mathcal{Y}$的随机变量。$P(X,Y)$是$X$和$Y$的联合概率分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习与分类算法\n",
    "\n",
    "#### 朴素贝叶斯算法原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：  \n",
    "训练数据$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$，其中$x_i=(x_{i}^{(1)},x_{i}^{(2)},...,x_{i}^{(n)})^{\\mathrm{T}}$,$x_{i}^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)} \\in \\{a_{j1},a_{j2},...,a_{jS_j}\\}$,$a_{jl}$是第$j$个特征可能取的第$l$个值，$j=1,2,...,n$,$l=1,2,...,S_j$,$y_i \\in \\{c_1,c_2,...,c_K\\}$,$x$是实例。\n",
    "\n",
    "输出：  \n",
    "实例$x$的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步:先计算先验概率及条件概率\n",
    "$${P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)}{N}},k=1,2,...,K$$\n",
    "\n",
    "$${P(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\\sum_{i=1}^{N}I(y_i=c_k)}}$$\n",
    "$$Sj=1,2,...,n;l=1,2,...,S_j;k=1,2,...,K$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步:对于给定的实例$x=(x^{(1)},x^{(2)},...,x^{(n)})$计算\n",
    "$${P(Y=c_k)}\\prod_{j=1}^{n}P(X^{(j)}|Y=c_k),k=1,2,...,K$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三步:确定实例$x$的类\n",
    "$${y=\\arg \\max_{c_k}P(Y=c_k)\\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_k)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对最终的朴素贝叶斯分类算法，如何求解$P(Y=c_k),P(X^{(j)}=x^{(j)}|Y=c_k)$,常见有三种模型：\n",
    "多项式模型、高斯模型、伯努利模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **多项式模型**\n",
    "当特征是离散时，使用多项式模型，多项式模型在计算先验概率$P(Y=c_k)$和条件概率$P(X^{(j)}=x^{(j)}|Y=c_k)$时，会做一些平滑处理，具体公式如下：\n",
    "$${P(Y=c_k)=\\frac{N_{c_k}+\\alpha}{N+k\\alpha}}$$\n",
    "\n",
    "其中$N$是总的样本个数，$k$是总的类别个数，$N_{c_k}$是类别$c_k$的样本个数，$\\alpha$是平滑值.\n",
    "$${P(X^{(j)}=x^{(j)}|Y=c_k)=\\frac{N_{c_k,x_i}+\\alpha}{N_{c_k}+n\\alpha}}$$\n",
    "\n",
    "其中$N_{c_k}$是类别$c_k$的样本个数，$n$是特征维数，$N_{c_k,x_i}$是类别$c_k$的样本中，第$i$维特征值是$x_i$的样本个数，$\\alpha$是平滑值。\n",
    "\n",
    "当**$\\alpha=1$**时，称作**$Laplace平滑$**；  \n",
    "当$0<\\alpha<1$时，称作**$Lidstone平滑$**；  \n",
    "当$\\alpha=0$时，不做平滑处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面是是scikit-learn库中多项式模型的朴素贝叶斯分类器实现代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "API Reference: http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n",
    "定义一个MultinomialNB类\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "class MultinomialNB(object):\n",
    "    \n",
    "    def __init__(self,alpha=1.0,fit_prior=True,class_prior=None):\n",
    "        \"\"\"\n",
    "        多项式模型的朴素贝叶斯分类器。多项式朴素贝叶斯分类器适用于具有离散特征的分类。\n",
    "\n",
    "        参数\n",
    "        ----------\n",
    "        alpha : 平滑参数(float类型)，默认为1.0;\n",
    "        如果alpha=0则不平滑。\n",
    "        如果 0 < alpha < 1 则为Lidstone平滑\n",
    "        如果 alpha = 1 则为Laplace 平滑 \n",
    "       \n",
    "        fit_prior : 布尔型\n",
    "        是否学习类别先验概率。\n",
    "        如果设置为False，将使用统一的优先权。\n",
    "        \n",
    "        class_prior : array-like, size (n_classes,)\n",
    "                类别的先验概率。如果指定，则不会根据数据调整优先级。\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior = class_prior\n",
    "        self.classes = None\n",
    "        self.conditional_prob = None\n",
    "    \n",
    "\n",
    "    def _calculate_feature_prob(self,feature):\n",
    "        values = np.unique(feature)\n",
    "        total_num = float(len(feature))\n",
    "        value_prob = {}\n",
    "        for v in values:\n",
    "            value_prob[v] = (( np.sum(np.equal(feature,v)) + self.alpha ) /( total_num + len(values)*self.alpha))\n",
    "        return value_prob\n",
    "\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        #TODO: check X,y\n",
    "\n",
    "        self.classes = np.unique(y)\n",
    "        #计算类别先验概率: P(y=ck)\n",
    "        if self.class_prior == None:\n",
    "            class_num = len(self.classes)\n",
    "            if not self.fit_prior:\n",
    "                self.class_prior = [1.0/class_num for _ in range(class_num)]  #uniform prior\n",
    "            else:\n",
    "                self.class_prior = []\n",
    "                sample_num = float(len(y))\n",
    "                for c in self.classes:\n",
    "                    c_num = np.sum(np.equal(y,c))\n",
    "                    self.class_prior.append((c_num+self.alpha)/(sample_num+class_num*self.alpha))\n",
    "\n",
    "        #计算条件概率 P( xj | y=ck )\n",
    "        self.conditional_prob = {}  # like { c0:{ x0:{ value0:0.2, value1:0.8 }, x1:{} }, c1:{...} }\n",
    "        for c in self.classes:\n",
    "            self.conditional_prob[c] = {}\n",
    "            for i in range(len(X[0])):  #for each feature\n",
    "                feature = X[np.equal(y,c)][:,i]\n",
    "                self.conditional_prob[c][i] = self._calculate_feature_prob(feature)\n",
    "        return self\n",
    "\n",
    "\n",
    "    #给定values_prob {value0:0.2,value1:0.1,value3:0.3,.. } and target_value\n",
    "    #返回target_value的概率\n",
    "    def _get_xj_prob(self,values_prob,target_value):\n",
    "        return values_prob[target_value]\n",
    "\n",
    "    #基于(class_prior,conditional_prob)预测单个样本\n",
    "    def _predict_single_sample(self,x):\n",
    "        label = -1\n",
    "        max_posterior_prob = 0\n",
    "\n",
    "        #对于每个类别，计算其后验概率: class_prior * conditional_prob\n",
    "        for c_index in range(len(self.classes)):\n",
    "            current_class_prior = self.class_prior[c_index]\n",
    "            current_conditional_prob = 1.0\n",
    "            feature_prob = self.conditional_prob[self.classes[c_index]]\n",
    "            j = 0\n",
    "            for feature_i in feature_prob.keys():\n",
    "                current_conditional_prob *= self._get_xj_prob(feature_prob[feature_i],x[j])\n",
    "                j += 1\n",
    "\n",
    "            #比较后验概率并更新最大后验概率，标签\n",
    "            if current_class_prior * current_conditional_prob > max_posterior_prob:\n",
    "                max_posterior_prob = current_class_prior * current_conditional_prob\n",
    "                label = self.classes[c_index]\n",
    "        return label\n",
    "\n",
    "    #样本预测(也可以是单样本预测)           \n",
    "    def predict(self,X):\n",
    "        #TODO1:check and raise NoFitError \n",
    "        #ToDO2:check X\n",
    "        if X.ndim == 1:\n",
    "                return self._predict_single_sample(X)\n",
    "        else:\n",
    "                #为每个样本进行分类 \n",
    "                labels = []\n",
    "                for i in range(X.shape[0]):\n",
    "                        label = self._predict_single_sample(X[i])\n",
    "                        labels.append(label)\n",
    "                return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多项式模型下的朴素贝叶斯分类算法测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([\n",
    "        [1,1,1,1,1,2,2,2,2,2,3,3,3,3,3],\n",
    "        [4,5,5,4,4,4,5,5,6,6,6,5,5,6,6]\n",
    "    ])\n",
    "X = X.T\n",
    "y = np.array([-1,-1,1,1,-1,-1,-1,1,1,1,1,1,1,1,-1])\n",
    "\n",
    "nb = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "nb.fit(X,y)\n",
    "print(nb.predict(np.array([2,4])))#输出-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **高斯模型  GaussianNB**\n",
    "\n",
    "  特征的可能性被假设为高斯\n",
    "  其概率密度函数：\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "\n",
    "  数学期望(mean)：$\\mu$  \n",
    "  方差：$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面是是scikit-learn库中高斯模型的朴素贝叶斯分类器实现代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯模型与多项式模型唯一不同的地方就在于计算 P(xi|yk)，高斯模型假设各维特征服从正态分布，需要计算的是各维特征的均值与方差。所以我们定义GaussianNB类，继承自MultinomialNB并且重载相应的方法即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianNB differ from MultinomialNB in these two method:\n",
    "# _calculate_feature_prob, _get_xj_prob\n",
    "class GaussianNB(MultinomialNB):\n",
    "     \n",
    "        #计算给定特征的平均值（mu）和标准偏差（sigma）\n",
    "        def _calculate_feature_prob(self,feature):\n",
    "                mu = np.mean(feature)\n",
    "                sigma = np.std(feature)\n",
    "                return (mu,sigma)\n",
    "\n",
    "        #高斯分布的概率密度 \n",
    "        def _prob_gaussian(self,mu,sigma,x):\n",
    "                return ( 1.0/(sigma * np.sqrt(2 * np.pi)) *\n",
    "                        np.exp( - (x - mu)**2 / (2 * sigma**2)) )\n",
    "\n",
    "        #给定mu和sigma，目标值返回高斯分布概率\n",
    "        def _get_xj_prob(self,mu_sigma,target_value):\n",
    "                return self._prob_gaussian(mu_sigma[0],mu_sigma[1],target_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **伯努利模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与多项式模型一样，伯努利模型适用于离散特征的情况，所不同的是，伯努利模型中每个特征的取值只能是1和0.（举例说明：在文本分类中，某个单词在文档中出现过，则其特征值为1，否则为0)\n",
    "\n",
    "在伯努利模型中，条件概率$P(X^{(j)}=x^{(j)}|Y=c_k)$的计算方式如下：\n",
    "\n",
    "当特征值$x^{(j)}=1$时，$P(X^{(j)}=x^{(j)}|Y=c_k)=P(X^{(j)}=1|Y=c_k)$\n",
    "\n",
    "当特征值$x^{(j)}=0$时，$P(X^{(j)}=x^{(j)}|Y=c_k)=1-P(X^{(j)}=1|Y=c_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**上述案例均已通过**\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "整理制作：深度学习学研社\n",
    "\n",
    "<div>\n",
    "<table align=\"left\" border=\"0\">\n",
    "    <div>\n",
    "    <tr>\n",
    "        <td>\n",
    "            微信公众号：ID: AI_class_vip<br>\n",
    "            <img src=\"../image/gongzhonghao.jpg\" width=\"150\" height=\"150\" align=\"left\"/>    \n",
    "        </td>\n",
    "    </tr>\n",
    "    </div>\n",
    "    <div>\n",
    "    <tr>\n",
    "        <td>\n",
    "        知识星球：机器学习交流学习圈：<br>\n",
    "    <img src=\"../image/dlzhishixingqiu.jpg\" width=\"150\" height=\"150\" align=\"left\"/>  \n",
    "        </td>\n",
    "    </tr>\n",
    "        </div>\n",
    "    <div>\n",
    "     <tr>\n",
    "        <td>\n",
    "        配置环境：python 3.4+  \n",
    "        </td>\n",
    "    </tr>\n",
    "        </div>\n",
    "</table>\n",
    "</div>\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
